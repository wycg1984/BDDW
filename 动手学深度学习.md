# 动手学深度学习

学习深度学习关键是**动手**

深度学习是人工智能最热的领域

核心是神经网络

神经网络是一门语言

应该像学习Python/C++一样学习深度学习



**目标：**

介绍深度学习经典和最新模型

​	LeNet、RestNet、LSTM、BERT、......

机器学习基础

​	损失函数、目标函数、过拟合、优化

实践

​	使用pytorch实现介绍的知识点

​	在真实数据上体验算法效果



**内容**

深度学习基础---线性神经网络、多层感知机

卷积神经网络--LeNet、AlexNet、VGGNet、Inception、RestNet

循环神经网络---RNN、GRN、LSTM、Seq2seq

注意力机制---Attention、Transformer

优化算法--SGD、Momentum、Adam

高性能计算---并行、多GPU、分布式

计算机视觉---目标检测、语义分割

自然语言处理---词嵌入、BERT



**你将学到：**

What  深度学习里与哪些技术 

How 如何实现和调参

Why 背后的原因(直觉、数学)



**AI地图**

![image-20210810113507506](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810113507506.png)

**应用：**

图片分类、物体检测与分割、样式迁移、人脸合成、文字生成图片、文字生成、无人驾驶、广告点击

![image-20210810114651445](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810114651445.png)

![image-20210810114739484](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810114739484.png)

![image-20210810115117509](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810115117509.png)

本地安装

【可选】使用conda/miniconda环境

```shell
conda env remove d2l-zh

conda create -n -y d2l-zh python=3.8 pip

conda activate d2l-zh
```

安装需要的包

```shell
pip install -y jupyter d2l torch torchvision 
```

下载代码并执行

```shell
wget https://zh-v2.d2l.ai/d2l-zj.zip

unzip d2l-zh.zip

jupyter notebook
```

## **数据操作**

1.N维数组样例

N维数组是机器学习和神经网络的主要数据结构

![image-20210810123555397](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810123555397.png)

![image-20210810123751545](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810123751545.png)

2.创建数据

​	需要：

​	形状：例如3 x 4矩阵

​	每个元素的数据类型：例如32位浮点数

​	每个元素的值：例如全是0，或者随机数

3.**访问元素**

![image-20210810124319377](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810124319377.png)

![image-20210810124334418](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210810124334418.png)

首先，导入torch

```python
import torch
```

张量表示一个数值组成的数组，这个数组可能有多个维度

```python
x = torch.arange(12)
x
```

可以通过张量的shape属性来访问张量的形状和张量中元素的总个数

```python
x.shape
```



```python
x.numel()
```

要改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数

```python
X = x.reshape(3,4)

X
```

使用全0、全1、其它常量或者从特定分布中随机采样的数字

```python
torch.zeros((2,3,4)) #3行4列
torch.ones((2,3,4)) 
torch.randn(3,4)
```

通过提供包含数值的Python列表(或嵌套列表)来为所需张量中的每个元素赋予确定值

```python
torch.tensor([2,1,4,3],[1,2,3,4],[4,3,2,1])
```

常见的标准算数运算符（+、-、*、/和**）都可以被升级为按元素运算

```python
x = torch.tensor([1.0,2,4,8])

y = torch.tensor([2,2,2,2])

x + y,x - y,x * y, x / y,x**y
```

按元素的方式应用更多的计算

```python
torch.exp(x) #指数运算
```

可以把多个张量连接起来

```python
X = torch.arange(12,dtype=torch.float32).reshape((3,4))

Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])

torch.cat((X,Y),dim=0)    #按行合并
torch.cat((X, Y), dim=1)  #按列合并
```

 通过逻辑运算符构建二元张量

```python
X == Y
```

对张量中的所以元素进行求和会产生一个只有一个元素的张量

```python
X.sum()
```

即使形状不同，仍然可以通过调用广播机制（broadcasting mechanism）来执行按元素操作

```python
a = torch.arange(3).reshape((3,1))

b = torch.arange(2).reshape((1,2))

a,b

a + b
```

可以用[-1]选择最后一个元素，可以用[1:3]选择第二个和第三个元素

```python
X[-1] , X[1:3]
```

除读取外，还可以通过指定索引来将元素写入矩阵

```python
X[1，2] = 9 #第一行第二列的元素修改成9

X
```

为多个元素赋予相同的值，只需要索引所有元素，然后为它们赋值

```python
X[0:2, :] = 12 #把第0行和第一行的所有列选中 替换成12

X
```

运行一些操作可能会导致为新结果分配内容

```python
before = id(Y)

Y = Y +　Ｘ

id(Y) == before
```

执行原地操作

```python
Z = torch.zeros_like(Y)

print('id(Z):',id(Z))

Z[ : ] = X + Y

print('id(Z):', id(Z)) 
```

如果在后续计算中 没有重复使用X，我们也可以使用X[ : ] = X + Y或X += Y来减少操作的内存开销

```python
before = id(X)

X += Y

id(X) == before
```

转换为NumPy张量 

```python
A = X.numpy()

B = torch.tensor(A)

type(A), type(B)
```



将大小为1的张量转换Python标量

```python
a = torch.tensor([3.5])

a,	a.item(),	float(a),	int(a)
```



## **数据预处理**

创建一个人工数据集，并存储在csv(逗号分隔符)文件

```python
import os 

os.makedirs(os.path.join('..','data'),exist_ok=True)

data_file = os.path.join('..','data','house_tiny.csv')

with open(data_file,'w') as f:

	f.write('NumRooms,Alley,Price\n') #列名

	f.write('NA,Pave,127500\n')	#每行表示一个数据样本

	f.write('2,NA,106000\N')

	f.write('4,NA,178100\n')

	f.write('NA,NA,140000\n')
```

从创建的csv文件中加载原始数据集

```python
import pandas as pd

data = pd.read_csv(data_file)

print(data)
```

为了 处理缺失的数据，典型的方法包括插值和删除，这里，我们考虑插值

```python
inputs,outputs = data.iloc[:,0:2],data.iloc[:, 2]

inputs = inputs.fillna(inputs.men())
print(inputs)
```

对于`inputs`中的类别值或离散值，我们将“NaN”视为一个类别

```
inputs = pd.get_dummies(inputs,dummy_na = True)
print(inputs)
```

现在`inputs`和`outputs`中的所有条目都是数值类型，它们可以转换为张量格式

```
import torch
X,y = torch.tensor(inputs.values),torch.tensor(outputs.values)
X,y
```

## 线性代数

**标量**

简单操作

​			c = a + b 

​			c = a · b

​			c = sin a

**长度**

![image-20210917091120368](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091120368.png)



**向量**

![image-20210917091201428](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091201428.png)

![image-20210917091304307](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091304307.png)

![image-20210917091326255](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091326255.png)

**矩阵**

![image-20210917091356808](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091356808.png)

![image-20210917091418248](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091418248.png)

![image-20210917091445366](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091445366.png)

![image-20210917091505033](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091505033.png)

![image-20210917091523761](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091523761.png)

**特殊矩阵**

![image-20210917091612576](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091612576.png)

![image-20210917091634318](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091634318.png)

![image-20210917091709313](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210917091709313.png)

标量由只有一个元素的张量表示

```python
import torch

x = torch.tensor([3.0])
y = torch.tensor([2.0])
x + y, x * y, x / y, x ** y
```

可以将向量视为标量值组成的列表

```python
x = torch.arange(4)

x
```

通过张量的索引来访问任一元素

```python
x[3]
```

访问张量的长度

```python
len(x)
```

只有一个轴的张量，形状只有一个元素

```python
x.shape
```

通过指定两个分量m和 n来创建一个形状为m×n的矩阵

```python
A = torch.arange(20).reshape(5,4)
A
```

矩阵的转置

```python
A.T
```

*对称矩阵*（symmetric matrix）A等于其转置：A=A⊤

```python
B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]])
B
B.T
```

就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构

```python
X = torch.arange(24).reshape(2,3,4)
X
```

给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量

```python
A = torch.arange(20,dtype = torch.float32).reshape(5,4)
B = A.clone()
A, A + B
```

两个矩阵的按元素乘法称为*哈达玛积*（Hadamard product）（数学符号⊙）

```python
A * B

a = 2
X = torch.arange(24).reshape(2, 3, 4)
a + X, (a * X).shape
```

计算其元素的和

```python
x = torch.arange(4, dtype=torch.float32)
x, x.sum()
```

表示任意形状张量的元素和

```python
A.shape, A.sum()
```

指定张量沿哪一个轴来通过求和降低维度

```python
A_sum_axis0 = A.sum(axis=0)
A_sum_axis0, A_sum_axis0.shape

A_sum_axis1 = A.sum(axis=1)
A_sum_axis1, A_sum_axis1.shape

A.sum(axis=[0, 1])
```

一个与求和相关的量是*平均值*（mean或average）

```python
A.mean(), A.sum() / A.numel()

A.mean(axis=0), A.sum(axis=0) / A.shape[0]
```

计算总和或均值时保持轴数不变

```python
sum_A = A.sum(axis=1, keepdims=True)
sum_A
```

通过广播将`A`除以`sum_A`

```python
A / sum_A
```

某个轴计算`A`元素的累积总和

```python
A.cumsum(axis=0)
```

点积是相同位置的按元素乘积的和

```python
y = torch.ones(4, dtype=torch.float32)
x, y, torch.dot(x, y)
```

我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积

```python
torch.sum(x * y)
```

矩阵向量积AxAx是一个长度为mm的列向量，其第ii个元素是点积a⊤ix

```python
A.shape, x.shape, torch.mv(A, x)
```

我们可以将矩阵-矩阵乘法ABB看作是简单地执行m次矩阵-向量积，并将结果拼接在一起，形成一个n×m阵

```python
B = torch.ones(4, 3)
torch.mm(A, B)
```

L2*范数*是向量元素平方和的平方根：

```python
u = torch.tensor([3.0, -4.0])
torch.norm(u)
```

L1范数，它表示为向量元素的绝对值之和：

```python
torch.abs(u).sum()
```

矩阵 的*弗罗贝尼乌斯范数*（Frobenius norm）是矩阵元素平方和的平方根：

```python
torch.norm(torch.ones((4, 9)))
```

矩阵计算

