# 数仓架构与实战

## 一、数据仓库的概念和ER实体模型

### 1、基于大数据的数仓建设

​	**1.1 什么是数据仓库**

​		什么是数据库

​		数据库(Database)是按照**数据结构**来**组织**、**存储**和**管理**数据的建立在**计算机**存储设备上的仓库。

​		数据库是长期储存在**计算机内**、**有组织**的、**可共享**的**数据集合**。数据库中的数据指的是以一定的数据模型组织、描述和储存在一起、具有尽可能小的冗余度、较高的数据独立性和易扩展性的特点并可在一定范围内为多个用户共享。

定义：面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策。

![image-20210802164005061](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802164005061.png)

​	**认识数据仓库**

![image-20210802164845659](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802164845659.png)

​	组织和结构就是建模的过程。

​	把所有系统的数据整合起来，按照一定的组织结构组织起来，形成一个仓储平台，即数仓平台。

​	比如要反映今天的交易额或者交易笔数这种概念就从数仓里面取，这时候并不代表说业务里有一个状态的变化，你要立刻更新到数仓里。

​	做数仓的时候有一个概念叫数据通道，数据通道就是负责做数据集成的。它会把各个数据接到通道里，通过通道往数仓的缓冲层里放。

![image-20210802172112942](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802172112942.png)

​	面向业务的数据库常称作OLTP，面向分析的数据仓库称为OLAP。

### 	**1.2 数据仓库的发展历史**

​		数据仓库概念最早可追溯到20世纪70年代，希望提供一种架构将业务处理系统和分析处理分为不同的层次。

​		20世纪80年代，建立TA2(Technical Architecture2)规范，该明确定义了分析系统的四个组成部分：数据获取、数据访问、目录、用户服务。

​		1988年，IBM第一次提出信息仓库的概念：一个结构化的环境，能支持最终用户管理其全部的业务，并支持信息技术部门保证数据质量；抽象出基本组件：数据抽取、转换、有效性验证、加载、cube开发等，基本明确了数据仓库的基本原理、框架结构，以及分析系统的主要原则。

​		1991年，Bill Inmon出版《Building the Data Warehouse》提出了更具体的数据仓库原则：

- 数据仓库是面向主题的

- 集成的

- 包含历史的

- 不可更新的

- 面向决策支持的

- 面向全企业的

- 最明细的数据存储

- 数据快照式的数据获取

  尽管有些理论目前仍有争议，但凭借此书获得"数据仓库之父"的殊荣。

  Bill Inmon主张自上而下的建设企业数据仓库，认为数据仓库是一个整体的商业智能系统的一部分。一家企业只有一个数据仓库，数据集市的信息来源出自数据仓库，在数据仓库中，信息存储符合第三范式，大致架构如下：

![image-20210802174524191](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802174524191.png)

Ralph Kimball出版的《The Data Warehouse Toolkit》，其主张自下而上的建立数据仓库，极力推崇建立数据集市，认为数据仓库是企业内所有数据集市的集合，信息总是被存储在多维模型当中，其思路如下：

![](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802175405615.png)

​		两种思路和观点在实际的操作中都很难成功的完成项目交付，直至最终Bill Inmon提出了新的BI架构CIF(Corporation information factory)，把数据集市包含了进来。CIF的核心是将数仓架构划分为不同的层次以满足不同场景的需求，比如常见的ODS、DW、DM等，每层根据实际场景采用不同的建设方案，该思路也是目前数据仓库建设的架构指南，但自上而下还是自下而上的进行数据仓库建设，并未统一。

![image-20210802182946392](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802182946392.png)



### 	**1.3 基于大数据数仓构建的特点**

​		随着我们从IT时代步入DT时代，数据从积累量也与日俱增，同时伴随着互联网的发展，越来越多的应用场景产生，传统的数据处理、存储方式已经不能满足日益增长的需求。而互联网行业相比传统行业对新生事物的接受度更高、应用场景更复杂，因此基于大数据构建的数据仓库最先在互联网行业中得到了尝试。

​		尽管数据仓库建模方法是一致的，但由于所面临的行业、场景的不同，在互联网领域，基于大数据的数据仓库建设无法按照原有的项目流程、开发模式进行，更多的是需要结合新的技术体系、业务场景进行灵活的调整，以快速响应需求为导向。

​	应用场景广泛

​		1、传统数据仓库建设周期长，需求稳定，面向DSS、CRM、BI等系统，时效性要求不高。

​		2、基于大数据的数据仓库建设要求快速响应需求，同时需求灵活、多变，对实时性有不同程度的要求，除了面向DSS、BI等传统应用外，还要响应用户画像、个性化推荐、机器学习、数据分析等各种复杂的应用场景。

​		技术栈更全面、复杂

​		传统数仓建设更多的基于成熟的商业数据集成平台，比如Teradata、Oracle、Informatica等，技术体系比较成熟完善，但相对比较封闭，对实施技术面要求也相对专业且单一，一般更多应用于银行、保险、电信等有钱行业。

​		基于大数据的数仓建设一般是基于非商业、开源的技术，常见的是基于hadoop生态构建，涉及技术比较广泛、复杂，同时相对于商业产品，稳定性、服务支撑比较弱，需要自己维护更多的技术框架。

​		技术栈转变

![image-20210802190055217](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802190055217.png)

​		数仓模型设计更灵活

​		传统数仓有较为稳定的业务场景和相对可靠的数据质量，同时也有较为稳定的需求，对数仓的建设有较为完善的项目流程管控，数仓模型设计有严格的、稳定的建设标准。

​		在互联网行业：

​				行业变化快、业务灵活，同时互联网又是个靠速度存活的行业。

​				源数据种类繁多：数据库、Nginx log、用户浏览轨迹等结构化、非结构化、半结构化数据。

​				数据质量相对差，层次不齐。

​	所以，在互联网领域，数仓模型的设计更关注灵活、快速响应和应对多变的市场环境，更加以快速解决业务、运营问题为导向，快速数据接入、快速业务接入，更不存在一劳永逸。

### **1.4 数据仓库的应用范围与场景**

​		数据存在的意义

​	![image-20210802194948916](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802194948916.png)

​	1、基于大数据的数据仓库在互联网行业主要的应用

![image-20210802195439477](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802195439477.png)

​	未来更广泛的应用场景

​	数据分析、数据挖掘、人工智能、机器学习、风险控制、无人驾驶

​	数据化运营、精准运营

​	广告精准、智能投放



### **1.5 发展方向**

​	行业就业、薪资

![image-20210802195904764](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802195904764.png)

## 二、实体关系(ET)建模理论及应用场景

### 1、数据仓库建模基本理论

数仓建模的目标

​		访问性能：能够快速查询所需的数据，减少数据I/O

​		数据成本：减少不必要的数据冗余，实现计算结果数据复用，降低大数据系统中的存储成本和计算成本。

​		使用效率：改善用户体验，提高使用数据的效率。

​		数据质量：改善数据统计口径的不一致性，减少数据计算错误的可能性，提供高质量的、一致的数据访问平台。

​	**所以，大数据的数仓建模需要通过建模的方法更好的组织、存储数据，以便在性能、成本、效率和数据质量之间找到最佳平衡点。**

​	**关系模式范式**

​		关系型数据库设计时，遵照一定的规范要求，目的在于降低数据的冗余性和数据的一致性，目前业界范式有：

- 第一范式（1NF）：域都应该是原子性的，即数据库表的每一列都是不可分割的原子数据项。![image-20210802210207510](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802210207510.png)![image-20210802210304581](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802210304581.png)
- 第二范式（2NF）：在1NF的基础上，实体的属性完全依赖于主关键字，不能存在仅依赖主关键字一部分的属性![image-20210802210506340](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210802210506340.png)![image-20210803084826266](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803084826266.png)
- 第三范式（3NF）：在2NF的基础上，任何非主属性不依赖于其它非主属性。目的在于消除传递函数依赖。![image-20210803085308351](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803085308351.png)
- 巴斯-科德范式（BCNF）
- 第四范式（4NF）
- 第五范式（5NF）

### 2、ER实体模型

​		在信息系统中，将事物抽象为"实体"、"属性"、“关系”来表示数据关联和事物描述；实体：Entity，关系：Relationship，这种对数据的抽象建模通常被称为ER实体关系模型。

​		实体：通常为参与到过程中的主体，客观存在的，比如商品、仓库、货位、汽车，**此实体非数据库的实体表**

​		属性：对主体的描述、修饰即为属性，比如商品的属性有商品名称、颜色、尺寸、重量、产地等。

​		关系：现实的物理事件是依附于实体的，比如商品入库事件，依附实体商品、货位，就会有"库存"的属性产生；用户购买商品，依附实体用户、商品，就会有"购买数量"、"金额"的属性产品。

​		实体之间建立关系时，存在对照关系：

​		1:1，即1对1关系，比如实体人、身份证，一个人有且仅有一个身份证号。

​		1:n，即1对多的关系，比如实体学生、班级，对于某1个学生，仅属于1个班级，而1个班级中，可以有多个学生。

​		n:macedonia:，即多对多的关系，比如实体学生、课程，每个学生可以选修多门课程，同样每个课程也可以被多名学生选修。

​		在日常建模过程中

​				"实体"用矩形表示

​				"关系"用菱形表示

​				"属性"用椭圆形表示

​		所以ER实体关系模型也称为E-R关系图

​		针对商品入库，ER图构建

​				抽象出实体				**商品	货位**

​				梳理实体间的关系 	**一个货位能存储多个商品，一个商品仅能放在一个货位**

​				梳理实体属性、关系属性 **商品：ID、名称、颜色、品类...**

​															**货位：位置、容量、存储条件...**

​															**入库关系：库存**



​				构建ER图

​		案例

​		场景：课程管理系统

​		该系统主要用来管理某校教师、学生、课程，其中包括课程选修、考试、教师授课、学生班级管理功能，现需要完成数据库逻辑模型设计。

​		1.抽象出主体

​		2.梳理主体之间的关系

​		3.梳理主体的属性

​		4.画出E-R关系图

E-R图

![image-20210803093227380](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803093227380.png)

IDEF1X

![image-20210803093410026](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803093410026.png)

**应用场景**

​		ER模型是数据库设计的理论基础，当前几乎所有的OLTP系统设计都采用ER模型建模的方式。

​		Bill Inmon提出的数仓理论，推荐采用ER关系模型进行建模

​		BI架构提出分层架构，数仓底层ods、dwd也多采用ER关系模型进行设计。



### 3、维度建模



DataVault模型



Anchor

## 三、Data Vault建模理论及应用场景

采集有全量采集、增量采集

![image-20210803100603465](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803100603465.png)

​		Data Vault是在ER模型的基础上衍生而来，模型设计的初衷是有效的组织基础数据层，使之易扩展、灵活的应对业务的变化，同时强调历史性、可追溯性和原子性，不要求对数据进行过度的一致性处理；并非针对分析场景所设计。

​		Data Vault模型是一种中心辐射式模型，其设计重点围绕着业务键的集成模式。这些业务键是存储在多个系统中的、针对各种信息的键，用于定位和唯一标识记录或数据。

### 1、**DataVault模型**

包含三种基本结构

- ​		中心表-Hub:唯一业务键的列表，唯一标识企业实际业务，企业的业务主题集合。只包含业务键信息以及数据装载的描述，不包含非键值以外的非业务数据属性本身；比如中心表商品，在DataVault下的设计：

![image-20210803105807996](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803105807996.png)

​		商品属性以及描述信息，都属于卫星表的范畴

- ​		链接表-Link:标识中心表之间的关系，通过链接表串联整个企业的业务关联关系。链接表用来描述中心表之间的关联关系，亦不包括业务键值以及数据装载描述以外的任何非键值数据，比如学生选课链接表，其设计：

  ![image-20210803110132191](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803110132191.png)

  ​		与选课相关的课时数德国描述信息，都属于卫星表的范畴

- ​		卫星表-Satellite:历史的描述性数据，数据仓库中数据的真正载体。数仓中数据的主要载体，包括对链接表、中心表的数据描述、数值度量等信息，中心表商品、订单明细的卫星表分别如下：

​	![image-20210803110334012](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803110334012.png)

**案例**

​		对上面已经讨论到的学生选课ER模型，进行DataVault模型重构，原模型：

![image-20210803110632506](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803110632506.png)

​		1.梳理所有主要实体

​		2.将有入边的实体定义为中心表

​		3.将没有入边且仅有一个出边的表定义为中心表

​		4.原系统没有入边且有两条或以上出边的表定义为链接表

​		5.将外键关系定义为链接表

![image-20210803112033298](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803112033298.png)

![image-20210803112207811](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803112207811.png)

![image-20210803112309568](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803112309568.png)

​	一个表可以存在多个卫星表。

​		按照Data Vault改造完成后的大概模型

![image-20210803114401831](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803114401831.png)

​		Data Vault模型更容易设计，ETL过程中更易配置化实现。Hub想象成人体的骨架，那么Link就是连接骨架的韧带组织，而satelite就是骨架上的血肉。

​		Data Vault是对ER模型更近一步的规范化，由于对数据的拆解和更偏向于基础数据组织，在处理分析类场景时相对复杂，适合数仓底层构建，目前实际应用场景较少。

### 2、**Anchor模型**

​		Anchor是对Data Vault模型做了更近一步的规范化处理，初衷是为了设计高度可扩展的模型，核心思想是所有的扩张只添加不修改，于是设计出的模型基本变成了k-v结构的模型，模型范式达到了6NF。

​		由于过度规范化，使用中牵涉到太多的join操作，目前没有实际案例，仅作了解。

​		以上为四种基本的建模方法，当前主流建模方法为：ER模型、维度模型

​		ER模型常用语OLTP数据库建模，应用到构建数仓时更偏重数据整合，站在企业整体考虑，将各个系统的数据按相似性一致性、合并处理，为数据分析、决策服务，但并不便于直接用来支持分析。

​		问题：

​		1.需要全名梳理企业所有的业务和数据流

​		2.实施周期长

​		3.对建模人员要求高



### 3、**维度模型**

​		维度模型是面向分析场景而生，针对分析场景构建数仓模型；重点关注快速、灵活的解决分析需求，同时能够提供大规模数据的快速响应性能。针对性强，主要应用于数据仓库构建和OLAP引擎底层数据模型。

​		不需要完整的梳理企业业务流程和数据。

​		实施周期根据主题边界而定，容易快速实现demo。

**CIF层次架构**

![image-20210803120937350](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803120937350.png)

ODS层一般都是关系型数据库过来的数据。

DWD层

DWS层

DM层

![image-20210803122131191](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803122131191.png)

​		1.数仓模型的选择是灵活的，不局限于某一种模型方法

​		2.数仓模型的设计也是灵活的，以实际需求场景为导向

​		3.模型设计要兼顾灵活性、可扩展，而对终端用户透明

​		4.模型设计要考虑技术可靠性和实现成本

拉链表  维度缓慢变化维

**数据仓库在实时场景的应用**

​		数据是有时效性的，不同时效的数据价值是不同的。

​		部分数据对更新时效性要求不高，比如用户年龄、性别、用户偏好、用户常驻位置，这部分数据随时间的变化不敏感，是不易发生变化的，所以数据价值随时间而衰退的速度较慢。

​		部分对时效性要求比较高，比如用户当前位置、周边拥堵情况，当前浏览的商品等，其应用场景就在于实时，数据价值随时间衰退较快，如果不能在短时间能快速处理或者分析应用，其价值将大大减小。

**按时效性，数据划分为：**

​		离线：数据延迟时间天级别，一般今天处理T-N天的数据，所有日常所说的数仓更多指的是离线部分，延迟1天，也称作T+1

​		准实时：数据延迟时间小时级别，一般今天处理H-N小时的数据，通常准实时延迟0.5、1小时

​		实时：数据延迟级别为毫秒、秒级别，可以理解为当前处理当前时刻的数据，实时计算、反馈

大数据体系下，离线、准实时、实时为数据仓库或者数据平台的子集，是数仓提供的统一整合。

​		离线、准实时，统一划归为离线处理即批处理，只是调度周期的粒度区别

​		实时，通常为独立常驻进程，实时处理数据流，也就是常说流式处理，实时有层次划分，有建模的过程。

实时场景

个性化推荐

​	实时：用户实时信息，比如位置、设备、当前会话浏览情况、最近的浏览的商品

​	离线：商品关联关系、用户相似性特征、位置偏好、设备偏好、关联偏好

用户画像

​	实时：实时位置标注、当前偏好标注、当前设备标注

​	离线：常驻位置、稳定偏好、常用设备、消费水平等标签

风控
	反欺诈、防刷单、薅羊毛等
	实时：用户位置、IP、设备、通讯录等
	离线：风险区域、风险用户、风险设备、多头等
需求场景越来越复杂和技术的发展，更对的数据价值得以快速的应用于企业的业务应用场景中的数据流通常会包括实时、离线、准实时的数据流程。

![image-20210803155337671](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803155337671.png)

## 四、大数据体系技术架构以及Hadoop、Spark基础架构

### 1、数仓技术架构

大数据领域内，数据仓库的建设解决根本的应用问题
1.实效性高
2.业务灵活、多变
3.数据源多样性
4.数据质量参差不齐
5.应用场景复杂

针对各种问题和场景，在做技术选型和底层技术架构的时候需要考虑：

​		1.梳理业务和相应的应用场景

​		2.需要处理的数据源的种类、类型、数据量

​		3.对时效性要求

​		4.对灵活性要求

​		5.对性能要求

​		6.对成本要求

没有包治百病的药，也没有解决所有问题的架构；同样没有最好的架构，只有更适合的架构；一个合理的架构的关键是能够在以下方面取得平衡：

​		1.满足需求

​		2.技术可持续

​		3.稳定性

​		4.可扩展性

​		5.成本

​		6.灵活性

![image-20210803161037812](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803161037812.png)

![image-20210803161046393](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803161046393.png)

![image-20210803161215097](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803161215097.png)

对大数据体系下基础建设工作，主要有：

大数据基础平台维护、基础运维、优化

​		不过度关注业务、数据内容本身，重点是集群的稳定性、性能、易用性，技术上会涉及底层源码，比如hadoop、spark、hbase等，大数据底层框架的维护角色---神秘但重要的底层建设者。

大数据生态开发、工程性开发、应用相关开发

​		关注业务逻辑或者特定应用场景，不关注或者仅关注特定的数据内容，大数据部分特定场景的应用开发，不会设计过多的底层技术，多为大数据基本框架的使用者，用各种技术服务于业务场景，比如推荐系统开发、OLAP引擎、反作弊等业务场景---无所不能的大数据开发者。

数据仓库、数据内容建设、开发

​		"大数据"真正的建设者，负责企业整体的数据资产建设和管理，负责数据治理体系，构建高质量、一致性、规范化的数据平台，关注企业整体业务情况和数据内容本身，对数据、业务有较高的敏感性，是所谓人工智能、自动驾驶等一切数据应用的底层基础数据建设者。

在整个大数据生态中，从应用上看

![image-20210803162702933](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803162702933.png)

**Hadoop**

Hadoop自发布以来，架构经历了三次大的调整，分别是hadoop1->hadoop2->hadoop3，当前主流为hadoop2版本，且Hadoop3截止目前没有稳定版本发布。

![image-20210803163806801](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803163806801.png)

Yarn，一个构建在N个节点的集群上的资源容器，负责集群中资源的统一管理，实现资源分配、调度，带有多种资源的分配、电镀策略，能够实现资源在不同应用上的隔离和优先级别分配。同时提供统一的资源入口，使得不同计算框架能够运行在一个yarn资源集群上，比如spark、MapReduce、impala、storm等，可以运行在同一个yarn集群上。

![image-20210803164033704](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803164033704.png)

yarn把整个集群中的CPU、内存等资源，整合为资源容器进行统一管理和调度；与之类似，HDFS系统在集群中DataNode节点的本地文件系统之上，构建为一个高可用性的、容错的、分布式的文件系统，文件系统的元数据由NameNode节点统一管理，实现对文件的定位、创建、删除等操作，同时负责各个DataNode节点的监听、负载均衡、副本复制等职责，因此NameNode是一个中心化的资源服务。

![image-20210803170338896](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803170338896.png)

mapreduce，一个分布式的编程模型，将输入数据切割成多个小的文件块，在多个进程中进行并行处理，这些进行可以是在同一台机器上，也可以分布在不同的机器上，以此实现分布式、并行处理，解决大数据、高吞吐的计算能力。

![image-20210803170652849](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803170652849.png)

**Resource Manager**

负责对各NodeManager的CPU、内存资源进行调度统一管理，包括调度器、应用程序管理器两部分

**Application Manager**

负责相关应用程序（Application Master）的跟踪、失败重启等，也负责向Resource Manager协调资源，一般每个yarn上的应用程序都包含一个AM  AM跟踪任务的状态、重试

**Node Manager**

每个节点有一个Node Manager，负责管理本地的Container，向Resource Manager汇报本节点的资源利用情况和Container的状态

![image-20210803173246594](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803173246594.png)

数据排重

![image-20210803173926304](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803173926304.png)

![image-20210805150850926](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805150850926.png)

Join

![image-20210805151054215](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805151054215.png)

**Spark**

spark，和MapReduce同样为分布式编程框架，不同之处在于MapReduce在计算过程中数据的交换、缓冲是存储在磁盘上的，而Spark在计算过程中数据的交换、共享是基于内存的，Spark将各个作业根据依赖形成DAG，满足条件的作业并行调度，可以理解为spark是基于内存的迭代式计算模型，相比较而言，spark提供了更丰富的算子操作，提供更简单的编程接口。

![image-20210805152040199](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805152040199.png)

​		与Hadoop相比，spark不包括文件系统，所以spark往往需要基于其它分布式文件系统，比如HDFS，S3等，同时spark几乎包含了大数据下所有场景的模块，形成了全栈的数据生态。

Spark三种运行模式

Standalone

![image-20210805162250031](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805162250031.png)

Yarn-client

![image-20210805162529482](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805162529482.png)

Yarn-cluster

![image-20210805162749987](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805162749987.png)

​		由于出色的性能和全栈式的体系，spark在目前的大数据体系内，已经成为主力成员，主要的应用场景包括：

​	实时计算；机器学习；图计算；数据挖掘；Ad-hoc

​		spark能够较好的融合实时、离线数据，因此在实时计算中的个性化推荐、智能广告投放风控等领域应用较多；在数据仓库建设中，尤其是ETL方面也有公司用它来替代Hive，但在较大数据量处理时，其稳定性略有欠缺，维护成本较高，所以目前hive依然是数据仓库ETL主力。

**Hive**

​		Hive是构建在hadoop之上的一个数据仓库平台，将结构化的数据映射为结构化的表，使用较为易用的SQL来处理数据，使用SQL来代替编程门槛较高的MapReduce，但本质上依然是将SQL转换为响应逻辑的MapReduce来对大规模数据进行分布式计算处理。

​		几乎在hive的同一时期，还有一种比较简单的MapReduce编程接口，即Pig；其通过简单的语义表达式来描述对数据的处理，为分析师或者ETL开发人员进行大规模数据处理大大降低了门槛，其执行过程依然是将语义描述转换为MapReduce进行简单的数据处理。由于SQL的普及率更高以及易用性，所以hive的发展更加迅速	



## 五、Hive体系结构与优化

### **1、Hive架构**

![image-20210805164416492](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805164416492.png)

### 2、Hive元数据的三种方案

**内嵌Derby方式**

使用内嵌的Derby库存储元数据，不能多用户并行操作，适合单机测试、学习

![image-20210805164912443](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805164912443.png)

安装hive后，默认使用该方案

**Local方式**

使用mysql、pg等RDBMS作为hive元数据存储介质，运行多用户并行操作，是较为常用的方式

![image-20210805165356473](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805165356473.png)

**Remote方式**

在元数据库上启动一个独立的metastore server，客户端通过metastore server与元数据库交互，对客户端隐藏数据库信息

![image-20210805165643773](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805165643773.png)![image-20210805165859642](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805165859642.png)

### 3、Metastore Server与HiveServer2

​		Metastore Server：

​				hive元数据的访问入口，使用thirft协议，提供对Hive元数据的跨语言访问

​		HiveServer2：

​				hive库中数据的访问入口，同样适用thirft协议，提供对hive中数据的跨语言访问，比如常见的python，Java等对hive数据的远程访问，beeline客户端也是通过HiveServer2方式访问数据

![image-20210805174031354](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805174031354.png)

### 4、数据类型

![image-20210805174233000](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805174233000.png)![image-20210805174830298](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805174830298.png)

### 5、Hive压缩格式

![image-20210805175544000](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805175544000.png)

文件可分割性：系统能够将文件无损的切割成多个小文件，在hadoop场景中，也就意味着一个大文件能否拆分成多个map任务并行处理

若文件本身可分割，但通过某种压缩方式进行压缩后，可能变得不可分割，这样会导致在MR中，单个task处理过大的文件从而影响性能

### 6、Hive文件格式

通常情况下，文件的存储格式有两种：行式存储、列式存储

行式存储，即存储以行为单位，常见的文件格式有textfile、SequenceFile、Avro

![image-20210805181031248](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805181031248.png)

列式存储，即存储以列为单位，常见的文件格式有rcfile、orc、parquet

![image-20210805181447956](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805181447956.png)

orc文件格式

![image-20210805181716684](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805181716684.png)

hadoop中的这几种列式存储，都是在Row group内的局部列式存储，在一定范围内降低筛选部分列的IO成本，但由于需要将整块缓存到内存中，如果面临全列读取到场景，其消耗更多的内存

### 7、Hive表类型

内部表

​		由hive完全控制，包括元数据和数据内容本身，数据会随着表的删除而删除。能够让hive对数据仓库中的数据管理更紧凑

外部表

​		hive仅维护了元数据的映射关系，无法控制数据内容，数据不会随着表的删除而删除，也就是说数据是由hdfs管理的。外部表的元数据与数据分开管理，使得数据能够更灵活、安全的管理，方便数据的共享

**表的选择**

- 在大部分场景下，两种表的应用没有太大的区别
- 数据场景简单，几乎都是在hive中流转，可以优先使用内部表
- 需要对数据内容和元数据进行紧凑的管理，建议内部表，比如复杂计算过程中用到的临时表，数据内容随用随删而油不希望关注底层文件
- 数据处理场景较多、复杂，建议采用外部表，比如需要用spark、mapreduce等处理复杂的数据，然后用hive做后续处理；需要处理非结构化日志数据的情况
- 需要对数据和元数据分开管理的场景，对数据安全性要求更高的场景，建议采用外部表

### 8、Hive事务

Hive在构建在Hadoopo生态中的数据仓库平台，适合于大规模、高吞吐的数据处理，提供基本的查询、分析能力，所以Hive并不是为事务、交易处理场景而存在的，在最初，hive并不支持事务；由于部分场景的需要，对hive进行了扩展，提供了基本的事务支持，但限制较多。

​		复杂的配置

​		文件格式必须是ORC

​		表必须分桶

​		对事务的支持不够完善，性能、稳定性欠缺

​		在数据仓库环境中，不建议使用hive事务;在数仓的场景中，需要hive事务的场景比较少，一般的场景都可以通过周期性的采集、数据处理来提供更高效、稳定的替代方案。

​		对于非常强的需求，建议考虑Hbase+Hive做整合，利用Hbase的实时写入以及事务支持的特性，Hive的hql易用并且高吞吐的能力，组合来满足相关场景的需求

## 六、Hive优化

### 1、Hbase 

​		基于hadoop的数据库，nosql库，基于HDFS实现高可用、分布式、列式存储，核心包括三部分：

​		RowKey

​		列族、列

​		时间戳

​	按照RowKey字典顺序存储，基于rowkey的高效检索，同时继承hdfs的高吞吐能力

​	Hbase使用rowkey快速访问数据，所以rowkey的设计是hbase性能提升的关键

​	hbase数据访问方式：

​	通过get方式，指定rowkey获取唯一一条记录

​	通过scan方式，设置startRow和stopRow参数进行范围匹配

​	全表扫描，即直接扫描整张表中所有行记录

Hbase Rowkey设计原则

​		Rowkey长度

​		Rowkey快速定位过程中，rowkey数据是在内存中的，所以rowkey过长时，如果数据量又很大，会导致内存占用量过多，检索变慢

​		hbase本身对rowkey限制64kb，但建议越短越好，最好16字节以内；另外colname对设计也同样尽量简单

​		Rowkey唯一性

​		rowkey需要能够唯一标识一条记录，类似于RDBMS中的主键，所以必须唯一

​		Rowkey散列

​		由于数据是按照rowkey的字典顺序存储的，若rowkey顺序性较强，会减弱hbase分布式存储的特点，造成数据热点，在高并发数据读写时，会造成部分regoin过载，严重时会造成节点失联，影响其它数据访问

​		散列的方案：

​		Hash	可以让数据均衡分布，可重构，可以使用get等方式快速访问数据

​		加随机数  数据均衡分布，不可重构，失去get快速定位数据等能力

​		反转  普遍使用的散列方法，尤其是对于时间序列、手机号类似的rowkey

​	二级索引

​		二级索引是hbase后期添加的索引类型，用来解决非rowkey数据访问场景，支持B树索引、位图索引，但hbase二级索引类型与mysql等普通索引不同

### 2、Hive SQL

​		**DDL**

​		Hive Cli![image-20210806081243713](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806081243713.png)

​	参数设置

```shell
##设置是否在map前合并小文件以减少map数
hive>set hive.hadoop.supports.splittable.combineinputformat=true;
##在Map-only的任务结束时合并小文件
hive>set hive.merge.mapfiles=ture;
##在Map-Reduce的任务结束时合并小文件
hive>set hive.merge.mapredfiles=true;
#使用tez引擎
hive>set hive.execution.engine=tez;
```

语法

```sql
CREATE DATABASE/SCHEMA,TABLE,VIEW,FUNCTION,INDEX
DROP DATABASE/SCHEMA,TABLE,VIEW,INDEX
TRUNCATE TABLE
ALTER DATABASE/SCHEMA,TABLE,VIEW
MSCK REPAIR TABLE(OR ALTER TABLE RECOVER PARTITIONS)
SHOW DATABASES/SCHEMA,TABLES,TBLPROPERTIES,PARTITIONS,FUNCTIONS,INDEX[ES],COLUMNS,CREATE TABLE
DESCRIBE DATABASE/SCHEMA,TABLE_NAME,VIEW_NAME

--e.g
--create table
create external table fact_loan_info
(
	id bigint comment '业务自增主键',
    loan_no string comment '借款编号',
    user_id bigint comment '',
    ......
)comment '借款信息表'
partitioned by (dt string)
row format delimited
--fields terminated by '\u001'
--lines terminated by '\n'
stored as orc
location '/apps/hive/warehouse/fact_tinyv.db/fact_loan_info';

--add partition
alter table table_name add partition(dt='yyyy-mm-dd') location '/apps/hive/warehouse/fact_tinyv.db/fact_loan_info';

--drop partition
alter table table_name drop if exists partition(dt='yyyy-mm-dd') ;
--drop table 
drop if exists table table_name 
```

​	

​	**DML**

```sql
insert overwrite table...
insert into table...
insert overwrite table ...partition(dt='',...)
insert into table ...partition(dt='',...)
create table tmp_xxx as select ...from ...

--select
join/left join/right join/full join
union/union all
group by/sort by/order by
distribute by/cluster by
limit

--多维
grouping sets
select a,b,count(1)...group by a,b grouping sets((a,b),(a),(b))
=group by a,b
 unoin all
 group by a
 union all
 group by b
 
--cube
select  a,b,count(1)...group by a,b with cube
= group by a,b grouping sets((a,b),(a),(b),())
= group by a,b
 unoin all
 group by a
 union all
 group by b
 union all
 select count(1)... 
 
 --rollup
 select  a,b,c,count(1)...group by a,b,c with roolup
 = grouping sets((a,b,c),(a,b),(a),())
 = group by a,b,c
 unoin all
 group by a,b
 union all
 group by a
 union all
 select count(1)... 
 
 --function 自定义函数
 Nvl/if/coalesce/isnull/isnotnull
 get_json_object/parse_url
 regexp_extract
 split/substring
 json_tuple/parse_url_tuple/lateral view...
 
 --window function 窗口函数
 row_number/rank/dense_rank
 count/sum/avg...
 lead/lag
 first_value/last_value
 select 
 	user_id
 	,create_time
 	,datediff(to_date(create_time),to_date(first_loan_time)) as day_diff_1 --本次申请借款距首次借款天数
 	,datediff(to_date(create_time),to_date(lag_loan_time)) as day_diff_1 --本次申请借款距上次借款天数
 from
 	(select
    	user_id
    	,create_time
    	,first_value(create_time) over (partition by user_id order by create_time) as first_loan_time
     	,lag(create_time ) over (partition by user_id order by create_time) as lag_loan_time
     from fact_tinyv.fact_loan_info
     where dt='2018-05-10'
 order by user_id,create_time
```

​		**合理使用UDF**

​		1、场景一：去重问题

​		union  union all   一般情况下使用union all性能更高

​		distinct  group by

```sql
select count(1) from 
(select name from (
select name from a
union all 
select name from b)) tab
group by name ) tabv
```

​		2、场景二：job数的问题

​		union all减少Job个数

​		夺标同join条件，减少Job数

​		3、场景三：合理控制并行

​		开启任务并行执行 set hive.exec.parallel= true;

​		允许并行任务的最大线程数 set hive.exec.parallel.thread.number=8;

​		union all

​		join 

​		4、场景四：任务数控制

​		**Map控制**

​		每个Map最大输入大小

​		set mapred.max.split.size=256000000;

​		一个节点上split的至少的大小

​		set mapred.min.split.size.per.node=100000000;

​		一个交换机下split的至少的大小

​		set mapred.min.split.size.per.rack=100000000;

​		执行Map前进行小文件合并

​		set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;

​		**Reduce控制**

​		每个reduce处理的数据量

​		set hive.exec.reducers.bytes.per.reducer=500000000;

​		制定reduce数量

​		set mapred.reduce.tasks=20;

​		**Reduce输出文件数**

​		map输入的小文件从哪里来，怎么避免map合并小文件

​		Reduce太多会导致作业生成小文件过多

​		小文件过多会降低namenode的性能

​		在Map-only的任务结束时合并小文件

​		set hive.merge.mapfiles=true;

​		在Map-Reduce的任务结束时合并小文件

​		set hive.merge.mapredfiles=true;

​		合并文件的大小

​		set hive.merge.size.per.task=256*1000 * 1000

​		输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件合并

​		set hive.merge.smallfiles.avgsize=16000000;

​		5、场景五：排序

​		order by、sort by ：order by全局排序；sort by局部排序

​		limit 

​		6、场景六 map多承担问题，减少reduce的计算成本和数据传输成本

​		Map Join

​		Map aggr

​		7、场景七：数据倾斜

​		空值问题

​		数据类型不一致

​		业务数据本身导致

​		8、场景八：数据裁剪

​		记录数裁剪：分区、分桶；无效记录map阶段剔除

​		列裁剪：剔除无效、非计算范围内的列数据；列式存储

​		9、场景九：减少IO

​		多表插入：

```sql
from a
insert overwrite table b
select col1,col2 where type='b'
insert overwrite table c
select col1,col  where type='c'
```

​		一次计算，多次使用

```sql
with tab1 as 
(select ... where ...group by...)
select
```



## 七、大数据仓库周边技术-Sqoop、Flume等

数据采集：DataX、Sqoop、Flume、rsyslog、logstash、filebeat等

数据通道：Kafka、RabbitMQ、ZeroMAQ

调度：Oozie、Azkaban、Airflow

### 1、数据采集

​		将目前主要的数据源分为数据库、日志、平面文件三种，针对每种数据源的特点，采用适当的采集方案，目前常用的主要开源产品如下

​		数据库：Sqoop、Datax

​		日志：flume、rsyslog、logstash、filebeat

​		平面文件：ftp、sftp、scp等

**Datax**

​		Ali开源的，基于多线程级别的并行实现离线、异构平台同步工具，能够快速实现异构数据源的离线同步。

![image-20210806100657630](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806100657630.png)

![image-20210806101059130](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806101059130.png)

支持数据示例广泛，灵活的实现各种结构存储之间的数据同步

部署、使用简单

能够实现流量精准控制

问题：一次读取，多个写入端？不是分布式的

**Sqoop**

Sqoop开源的、基于Mapreduce的、关系型数据库与HDFS之间数据同步工具，大数据生态中的关键组件，目前有sqoop1、sqoop2两个版本同步更新

![image-20210806101834152](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806101834152.png)

sqoop1：仅有一个客户端，架构简单明了，部署即用，使用门槛比较低；耦合性强，用户密码暴露导致不安全

sqoop2：服务端部署、运行，提供cli、rest api、web ui等入口，connector集中管理，RDBMS账号控制更安全，但sqoop2仅负责数据的读、写操作，架构相对复杂

**Datax VS Sqoop**

Datax ：支持更多的异构同步，多线程而非分布式，易于部署；开源版本仅提供单节点部署方案，任务较多容易产生性能瓶颈

Sqoop：支持RDBMS->HDFS、HDFS-->RDBMS的同步，支持场景有限，基于Mapreduce的分布式程序，方便弹性扩展

**Flume**

cloudera开源的实时日志采集系统，灵活易扩展，目前在大数据体系内，尤其是实时计算部分为重要生态组件。

![image-20210806104541453](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806104541453.png)

Flume包含3部分：

Source：负责根据配置策略，捕获event并投递到Channel中

Sink：从channel中消费数，投递到下一个目标端

Channel：一个暂缓event的数据通道，类似队列

场景一：日志归集

![image-20210806105711697](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806105711697.png)

场景二：load balance 负载均衡

![image-20210806105817093](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806105817093.png)

场景三：日志分流OR多路存储

![image-20210806105922940](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806105922940.png)

场景四：数据通道前置端

![image-20210806110024822](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806110024822.png)

场景五：Flume用做数据通道	

![image-20210806110123727](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806110123727.png)

### 2、**调度系统**

**Oozie**

oozie v1:workflow普通工作流，根据作业间的依赖关系构建成有向无环图，和其它的工作流无异

oozie v2:根据Coordinator协调工作流的执行，提供时间触发、数据触发

oozie v3:根据Bundle协调一批Coordinator的执行

与hadoop、hive、spark有较强的版本依赖关系，使用中版本升级等过程需注意jar冲突

案例分享

​		**背景：**互联网金融行业，主要经营网贷业务，业务中包括用户注册、授信、借款、还款等流程，涉及到的数据源包括用户行为数据、交易业务数据、三方合作数据等，存储介质包括log、mysql、PostgreSQL、Mongo，每日数据库中数据量800G，增速10G/天、表数100左右，日志量3T/天

​		需要满足数据仓库的周期性数据交换，包括采集与数据产出

​		需要满足三方合作数据实时风控特征计算

​		需要满足用户行为数据流的实时分析和计算

​		能够满足企业实时数据订阅、消息推送

​		

 **分析**：数据库的数据采集：mysql、mongo、postgresql

​		应用日志：log

​		用户行为数据：log或者实时数据流

​		三方合作数据：一般为接口实时数据

​		数据库的采集，可用方案sqoop、datax，sqoop不支持mongo数据采集

​		应用日志采集，可用flume、filebeat等

​		三方数据一般为接口返回，调用程序可充当采集端，对于落地的数据，根据落地位置采用合理的方案

​		通道可选Kafka、MQ等，flume亦可，要求按需订阅管理，高吞吐，选择kafka 

![image-20210806112034543](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806112034543.png)



## 八、数据采集与同步

![image-20210806112949953](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806112949953.png)

### 1、行为数据埋点设计

​		通常将数据分为两类：

​		1).业务数据：业务流程中产生的交易、状态流转、用户等相关的数据，通常存储在DB中，包括rdbms、nosql等，这部分数据是业务相关的，具体哪些数据需要保留一般由业务侧设计，不需要过度关注，按实际需要采集即可

​		2).用户行为数据：用户在使用产品过程中，与C端产品交互过程中产生的数据，比如页面浏览、点击、停留等，这部分数据由于不影响业务流程本身，所以通常不受关注，但对运营、产品优化至关重要，所以通常也是数据建设的一部分，需要单独设计数据埋点、采集策略

用户标识体系建设

​		注册独立用户账户：能够较完整的标识用户，产品层面影响用户的使用欲望，容易错过早期意向用户，对于访问但未注册部分，依然无法跟踪

​		注册独立用户账户&三方授权验证：降低用户进入门槛，可以获得用户注册前的行为，同时通过三方验证方案能够与三方进行更多数据合作的可能，但用户依然存在不愿验证的可能

​		**用户标识建立方案**

​		PC Web/H5：用户设备中 留存的cid(类似与cookeid)，若切换用户登陆或注册新账号，则cid发生变化，在用户注册前，登陆前作为设备标识，跟踪用户行为数据。用户注册、登陆后，使用uid标识用户，跟踪用户行为数据

​		APP：注册前、登陆前使用设备imei/IDfa根据某规则生成唯一设备标识；注册、登陆后使用uid标识用户

![image-20210806121320118](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806121320118.png)

**行为数据埋点设计**

![image-20210806121941089](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806121941089.png)

总体看，仅有两类：app native、web h5

埋点设计的时候，h5类的包括页面reffer、浏览等信息，但孤立的h5无法获取设备相关信息

Native原生开发，能获取更多的设备信息，对页面浏览、reffer等弱化

通常设计埋点时针对app native、h5采用不同的规范，但不利于数据整合和使用，推荐采用事件模型进行埋点设计，即把用户的一切行为动作都看作事件，包括页面浏览，这样native和h5统一数据标准，实际数据仅参数上的区别。

​		根据埋点位置，可分为客户端埋点、服务端埋点，实际各有利弊，比如服务端埋点对无后台请求的用户行为无法捕获，而客户端埋点可能会由于用户的环境问题存在数据包丢失，客户端可能无法获取全部的数据等，所以无特殊情况下，建议采用服务端埋点方案

​		用户与C端产品交互过程中，会产生大量的数据，过量的抓取会导致产品性能、用户体验下降，同时数据处理、存储成本极速上升，所以数据采集需要明确边界，具体参照业务需求、数据价值、企业数据规划确定

​	

​	**数据埋点日志规范：**

​	1.确保灵活、高可扩展

​	2.兼顾后续的处理分析的方便性

​	3.确保可跟踪、数据正确性

​	4.业务数据打通

​	5.考虑不同C端产品特性与用户体验

​	6.确保性能、敏感数据安全性

​	**埋点数据边界：**

​	1.至少满足当下运营、产品等也需求

​	2.用户固有信息规划之处采集完整

​	3.尽可能的和业务数据打通

​	4.尽可能的能够还原用户场景

​	5.在性能、用户体验等允许范围内，尽可能采集更多有意义的数据

​	**实战案例**

​	场景：某电商平台，产品覆盖app、h5、pc端，其中app为hybrid架构，业务数据存储在mysql库中

​	需求：需要分析用户访问路径、各步转化、流失等进行页面优化、运营效果评估

​	商品推荐；

​	反作弊策略：需要设备、IP等信息

​	实时流量大盘监控：热门商品、热门店铺、进店量等

**设计埋点规范**

一切用户操作行为都看作事件

覆盖事件的核心要素

![image-20210806124910036](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806124910036.png)

数据格式：

​	为确保灵活、可扩展，上报数据采用json格式，不要太深的嵌套，将数据分为两部分：公有参数、自定义私有参数

​	公有参数：需要覆盖事件核心要素，实际上报数据时不可缺失

​	私有参数：即根据事件发生时的场景、需求，定义需要抓取的数据内容；某种意义上该部分数据也分公共参数和私有参数，比如事件发生在app中，设备信息都会伴随当时的设备信息；事件发生在h5中，一般会伴随url

![image-20210806125148046](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806125148046.png)

对于一般的推广h5，需要抓取基本数据：currurl、refferurl、refferpage、sourceid、自定义参数(比如商品ID、活动ID、商家ID、posid等)

对于app，一般需要附加设备信息：

refferpage、自定义参数(比如商品ID、商家ID等)、设备信息（imei、idfa、os、gps、wifi等信息）

对于hybird APP，其中包括native和h5，虽然是h5，但由于在app中，依然能够拿到相关设备信息，因此按照app的参数设计进行埋点，同时也要包括h5自身的特有数据，比如url、refferurl

![image-20210806130248193](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130248193.png)

![image-20210806130434476](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130434476.png)多

![image-20210806130626033](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130626033.png)

![image-20210806130743371](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130743371.png)

![image-20210806130805685](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130805685.png)

### 2、数据采集方案设计

![image-20210806130855614](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130855614.png)

![image-20210806130919295](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130919295.png)

![image-20210806130939097](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806130939097.png)

![image-20210806131253665](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131253665.png)

![image-20210806131457740](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131457740.png)

![image-20210806131602394](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131602394.png)

![image-20210806131542957](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131542957.png)

![image-20210806131658723](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131658723.png)

![image-20210806131727745](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131727745.png)

![image-20210806131759622](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131759622.png)

![image-20210806131851673](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131851673.png)![image-20210806132051166](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132051166.png)

![image-20210806131948856](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806131948856.png)

![image-20210806132021339](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132021339.png)

![image-20210806132121625](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132121625.png)

![image-20210806132219425](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132219425.png)

![image-20210806132246117](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132246117.png)

数据质量

![image-20210806132524893](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132524893.png)

![image-20210806132505269](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132505269.png)

数据质量控制环节

![image-20210806132626286](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132626286.png)

![image-20210806132640091](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132640091.png)

![image-20210806132659083](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132659083.png)

![image-20210806132714657](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132714657.png)

![image-20210806132748701](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132748701.png)

![image-20210806132816925](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132816925.png)

![image-20210806132845573](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132845573.png)

![image-20210806132908862](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132908862.png)



元数据管理

![image-20210806132936004](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132936004.png)

![image-20210806132950389](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806132950389.png)

![image-20210806133053455](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806133053455.png)

![image-20210806133111028](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806133111028.png)

![image-20210806133159210](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806133159210.png)

![image-20210806133236718](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210806133236718.png)



![image-20210803174529555](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803174529555.png)

## 九、数据仓库与维度建模

![image-20210803174826039](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803174826039.png)

问题：

​		数据仓库，不针对某一个分析主题，而是有多个分析主题，即多个事实表，维度表怎么设计？

​		即使同一个分析主题，也可能存在多个事实表，维度表如何设计？多个时间维度？

**星座模型**

无论星型模型、雪花模型还是星座模型，都是针对维度上的区别而来，星座模型实质上还是星型模型，只是共用了维度

### 1、维度设计

​	**代理键**

​		维度表中必须有一个能够唯一标识一行记录的列，通过该列维护维度表与事实表之间的关系，一般在维度表中业务主键符合条件可以当作维度主键

​		问题：

​		当整合多个数据源的维度时，不同数据源的业务主键重复增么办

​		涉及维度拉链表时，同一主体对调记录，业务键重复怎么办

![image-20210803175613426](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803175613426.png)![image-20210803175914647](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803175914647.png)

id :是业务键本身 

​		把多个系统的聚合在一起，同时在维护一个独立的代理键，这个代理键在整个维度表里是唯一标识这一行记录的。代理键通常使用数值型的，自增的方式做的保证全局的唯一。
gid:独立的代理键

​	代理键：是由数据仓库处理过程中产生的、与业务本身无关的、唯一标识维度表中一条记录并充当维度表主键的列，也是描述维度表与事实表关系的纽带，所以在设计有代理键的维度表中，事实表中的关联键是代理键而不是原有的业务主键，即业务关系是靠代理键维护，这样有效避免源系统变化对数仓数据的影响。

​		在实际业务中，代理键通常是数值型、自增的值

​		问题：传统数据库有自增id，但Hive中怎么生成自增的代理键

```sql
--对商品维度表，生成自增代理键
insert overwrite into dim_goods_d partition(dt='2018-06-01')
select tb.* from 
tmp_s_inc as tb,
row_number() over(order by id)+ta.max_id as gid 
cross join (
select coalesce(max(gid),0) as max_id from dim_goods_d where dt ='2018-05-31'
) as ta 
union all 
select * from dim_goods_d where dt ='2018-05-31'
```

​	**稳定维度**

​		部分维度表的维度是在维度表产生后，属性是稳定的、无变化的；比如时间维度、区域维度等，针对这种维度，设计维度表的时候，仅需要完整的数据，不需要天的快照数据，因为当前数据状态既是历史数据状态

​	![image-20210803182037889](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803182037889.png)



**缓慢变化维度**

​		维度数据会随着时间发生变化，变化速度比较缓慢，这种维度数据通常称作缓慢变化维；由于数据仓库需要追溯历史变化，尤其是一些重要的数据，所以历史状态也需要采取一定的措施进行保存

​		每天保存当前数据的全量快照数据，该方案适合数据量较小的维度，使用简单的方式保存历史状态

​		在维度表中添加关键属性值的历史字段，仅保留上一个的状态值![image-20210803182619713](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803182619713.png)

**拉链表**

​		当维度数据发生变化时，将旧数据设置为失效，将更改后的数据当作新的记录插入到维度表中，并开始生效，这样能够记录数据在某种粒度上的变化历史![image-20210803183142403](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803183142403.png)

```sql
select * from user where start_date<=2018-05-22
and end_date>=2018-0522
```

![image-20210803185754557](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803185754557.png)

​		因为是对维度表做拉链，所以同一个维度实体必然存在多条记录，此时维度表的原子性主键就不存在了

​		拉链表怎么和事实表关联？添加代理键

![image-20210803193557817](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803193557817.png)

```sql
--按部门统计
select tb.Dept,Count(1)  from fact_order ta 
join dim_user tb on ta.uid = tb.uid  group by tb.dept

--按用户统计
select tb.id,count(1) from fact_order ta 
join dim_user tb  on ta.uid = tb.uid
group by tb.id
```

问题：事实表来源与业务事务表，代理键和业务本身没有关系，那么怎么在事实表中装载代理键

事实表中历史的用户维度ID不会发生变化，所以事实表的代理键加载仅发生在新增数据上

案例：对上述的事实表，装载用户维度代理键

```sql
---事实表装载代理键
select *from
(select
ta.*,tb.uid
from fact_order as ta
join dim_user as tb
on ta.id = tb.id) tmp
where created_time>= start_date and created_time<=end_date
```

缓慢变化维度

​		代理键是维度建模中极力推荐的方式，它的应用能有效的隔离源端变化带来的数据结构不稳定问题，同时也能够提高数据检索性能。

​		但是如你所见，代理键维护代价非常高，尤其是数据装载过程中，对事实表带来了较大的影响，在基于hive的数据仓库建设影响更加严重，比如代理键的生成、事实表中关联键的装载、不支持非等值关联等问题，带来ETL过程更加复杂

​		故，在大数据体系下，谨慎使用代理键，同时对于缓慢渐变的维度场景，可以考虑用空间换时间，每天保留维度全量快照；但这样会带来存储成本，根据实际情况衡量。

​		**维度表的拆分、合并**

​		公司用户维度

![image-20210803202003557](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803202003557.png)

案例

​		针对公司员工进行维度设计：公司包括销售体系、技术体系、行政体系、物流体系等，很多部门都关注公司员工的信息，比如物流体系要分析人员发货错误率、人员效率等，财务部门关注员工薪资、待遇以便分析财务预算等，HR关注薪资待遇以方便评估公司人才计划等。

​		从另一个角度看，销售体系员工有相应的销售区域划分、技术体系员工有相应的技术方向等。![image-20210803202937173](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803202937173.png)



### 2、事实表设计

​	**明细事实表**

​	事实表有粒度大小之分，基于数据仓库层次架构，明细事实表一般存在于dwd层，该层事实表设计不进行聚合、汇总动作，仅做数据规范化、数据降维动作，同时数据保持业务事务粒度，确保数据信息无丢失

​	**数据降维**：为了提高模型易用性，将常规维度表中的常用的属性数据冗余到相应的事实表中，从而在使用的时候避免维表关联的方式，即为数据降维

案例：订单表

在业务中，有比较频繁的应用场景，即分析各商品类别的销量、按区域分析购买力等

![image-20210803204647566](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803204647566.png)

事实表中不一定有事实

一般将事实表中包含两部分信息：维度、度量，度量即为事实，但有些特殊情况下，事实表中无度量信息，只是记录一个实际业务动作

​	比如：信息审核表

![image-20210803205151049](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803205151049.png)![image-20210803211005484](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210803211005484.png)

​		设计事实表的主要依据是业务过程，之前说过，每一个业务动作事件，都可以作为一个事实，那么在一个订单处理过程中，会有多个动作，这个过程中的事实表如何设计？

​		方案一：单事件事实表

​		对于每一个业务动作事件，设计一个事实表，仅记录该事件的事实以及状态

​		方案二：流程事实表

​		对于一个业务流程主体，设计一个事实表，跟踪整个流程的事实以及状态流转

​		场景案例

​		出行领域，用户下单打车，该订单的整个流程包括用户下单、司机接单、司机做单、乘客支付，可能还伴随有评价、投诉等环节，这个场景下的明细事实表怎么设计

​		![image-20210804081940876](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804081940876.png)![image-20210804082340893](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804082340893.png)

流程事实表

![image-20210804082651390](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804082651390.png)

单事件事实表：

更方便跟踪业务流程细节数据，针对特殊的业务分析场景比较方便和灵活，数据处理上也更加灵活；不方便的地方就是数仓中需要管理太多的事实表，同时跟踪业务流转不够直观。

流程事实表：

能够更直观的跟踪业务流转和当前状态，流程事实集中，方便大部分的通用分析应用场景，由于和业务侧的数据模型设计思路一致，也是目前最常用的事实表设计；但是细节数据跟踪不到位，特殊场景的分析不够灵活

两种表的设计区别在于对业务流程的拆分思路不同，具体选择事实表的构建思路，需要根据实际的业务确定，一般建议两者结合。

**事实表设计方案**

​		增量存储：即每周期仅处理增量部分的数据，针对状态无变化的数据比较合适

​		全量快照：状态有变化，但每天保存当前的快照数据，对于数据量在可控范围内的情况可以采用

​		保存策略：

- - 如果存储空间和成本可接受，完整存储，确保能够追溯到历史每天数据状态

  - 存储空间有限，考虑移动历史快照数据到冷盘，需要使用的时候可恢复

  - 数据历史状态数据无太大价值，可以考虑部分删除，比如保留每月最后一天的快照数据

  拉链

  ​		数据量大，但缓慢变化，需要跟踪历史状态，和缓慢渐变维类似

  **事实表设计方案**

  案例：信用卡场景，由于用户的信用额度、已用额度存在缓慢的变化，又需要跟踪变化的记录，设计相关事实表

  源数据包括：用户Id、卡id、额度、已用额度、剩余额度、创建时间、更新时间

  ```sql
  ---事实拉链表
  credit_amount,card_id,
  user_id,amount,used_amount,
  created_time,update_time
  ---1.采集增量数据s_credit_amount
  select col_name from table_name where update_time>='2018-06-01 00:00:00'
  ---2.dwd拉链表d_credit_amount 
  drop table if exists tmp_credit_amount
  
  create table tmp_credit_amount as 
  select * from (
  select 
  ta.card_id,
  ta.user_id,ta.amount,ta.used_amount,
  ta.created_time,ta.update_time,
  ta.start_date,
  (case when tb.card_id is not null and ta.end_date>'2018-06-01' then '2018-05-31' else ta.end_date) as end_date,
  load_time
  from
  d_credit_amount _1 as ta 
  left join 
  s_credit_amount as tb
  on ta.card_id = tb.card_id
  union all 
  select
  ta.card_id,
  ta.user_id,ta.amount,ta.used_amount,
  ta.created_time,ta.update_time,
  '' as start_date,
  '' as end_date,
  unix_timestamp() as load_time
  from s_credit_amount as ta) tmp
  
  insert overwrite into d_credit_amount_1
  select * from tmp_credit_amount;
  ```

  

```sql
	---基于全量快照数据做拉链
	dwd:d_credit_amount_d --->d_credit_amount_1
card_id,user_id,amount,used_amount,
created_time,update_time
---1.获取上日发生变化的数据
select * from 
(select 
ta.card_id,
ta.user_id,
ta.amount,
ta.used_amount,
ta.created_time
md5(concat(card_id,user_id,user_id,used_amount,created_time)) as md5_flag
from d_credit_amount_d as ta 
where dt='2018-06-01') ta
left join
(select 
ta.card_id,
ta.user_id,
ta.amount,
ta.used_amount,
ta.created_time
md5(concat(card_id,user_id,user_id,used_amount,created_time)) as md5_flag
from d_credit_amount_d as ta 
where dt = '2018-05-31') tb
on ta.card_id = tb.card_id
where ta.md5!=tb.md5 or tb.card_id is null
```

​	**聚合事实表**

​	相对于明细事实表，聚合事实表通常是在明细事实表的基础上，按照一定的粒度粗细进行的汇总、聚合操作，它的粒度较明细数据粒度粗，同时伴随着细节信息的丢失；在数仓层次结构中，通常位于dws层，一般作为通用汇总数据存在，也可以是更高粒度的指标数据。但同一事实表中，尽可能保证事实粒度一致

​		日粒度

​		周期性累积

​		历史累积

​		可累加事实：在一定的粒度范围内，可累加的事实度量，比如：订单金额、订单数

​		不可累加事实：通常情况下，在更高粒度上不可累加的事实，比如通过率、转化率、下单用户数

​		通常情况下，比率这种不可累积的事实，建议拆分存储，比如通过率拆分为通过数、申请数，由细粒度数据去重计算而来事实，正常存储，但是更粗粒度累积是不可直接使用



​		数据仓库中，按照日期范围的不同，通常包括以下类别的聚合事实表

​		**公共维度层--通用汇总**

​		应对大部分可预期的、常规的数据需求，通常针对模式相对稳定的分析、BI指标计算、特征提取等场景，封装部分业务处理、计算逻辑，尽量避免用户直接使用底层明细数据，该层用到的数据范围比较广泛

​		**日粒度**

​		主要应对模式稳定的分析、BI日报、特征提取场景，同时日粒度也为后续累积计算提供粗粒度的底层，数据范围一般为上一日的数据

​		**周期性累积**

​		主要应对明细的周期性分析、BI周期性报表，数据范围一般在某周期内

​		**历史累积**

​		顾名思义，历史以来某一特定数据的累积，通常在用户画像、经营分析、特征提取方面场景较多，设计数据范围比较广泛，通常是计算耗时较长的一部分，比如某门店累积营业额、某用户累积利润贡献、用户首次下单时间(非可度量、描述性)

​		场景案例

​		按照出行订单明细事实表，构建数据仓库上层模型![image-20210804154023543](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804154023543.png)

![image-20210804153830834](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804153830834.png)

![image-20210804154434309](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804154434309.png)

![image-20210804154626629](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804154626629.png)

```sql
---首次下单
first_value()
row_number() over(partition by user_id order by created_time asc) as rn 
```

### 3、数据集市

数据仓库集市设计

​		在大数据数据仓库领域内，数据仓库是包括集市的，而且物理上是统一的、非隔离的，集市的概念相较于传统数据仓库比较弱化，由于有底层明细数据、通用汇总数据的存在，数据集市一般仅在上层应用层面存在相应分析主题的概念，甚至很大程度上存在集市交叉现象，所以如果是在大数据领域构建企业整体数据仓库，并且数据集市也一块规划，建议集市弱化，把它当作是梳理上层数据域的工具。

​		**主题设计思路**

​		按使用部门划分集市主题

​		按业务模块划分集市主题



## 十、实战案例-偏业务型行业数据仓库设计

### 1、背景

​		互联网信用贷款行业，主要业务流程：

​		用户注册 后，需要通过一系列的信息项认证

​		信息项认证成功后，可以申请授信，然后由风控策略、模型给出信用评定，同时给予相应的额度

​		用户获取额度后可以在平台发起贷款

​		贷款也要再次通过相应的风控模型，评级通过后可以放款

​		用户收到放款后，需要分期还款，每期归还一定的额度

![image-20210804161125532](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804161125532.png)

![image-20210804161658136](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804161658136.png)

1.梳理业务流程

2.梳理数据流

3.数据类型、存储介质、样例数据

4.需求---功能性需求、非功能性需求(性能、时效性)



rdbms  log  nginx  



![image-20210804164840999](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804164840999.png)

风控

![image-20210804164912884](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804164912884.png)

### 2、数据采集方案  MySQL

1.表的数据量、每日增量、updated_time/created_time，自增的id，源表的索引情况

```sql
	--split-by  id 全量采集
	--split by updated_time 增量采集

	select min(id),max(id) from table_name where ...

	--map 4  怎么分配数据量

	(max(id)-min(id))/4
```

 2.数据采集方案

增量(流水、updated)、全量

user：全量采集 		申请授信：增量采集 		额度：全量采集	借款、还款计算：增量采集	

3，数据仓库模型设计

抽象维度

​	![image-20210805081434720](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805081434720.png)![image-20210805081540549](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805081540549.png)

![image-20210805081833271](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805081833271.png)

![image-20210805081915935](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805081915935.png)

![image-20210805082037527](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805082037527.png)

![image-20210805082301440](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805082301440.png)

![image-20210805082429164](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805082429164.png)

![image-20210805082503515](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805082503515.png)





## 十一、偏流量型互联网行业数据仓库设计大数据仓库在数据化运营中的应用

**公共汇总层**

![image-20210805083514226](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805083514226.png)

![image-20210805083647141](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805083647141.png)

![image-20210805084732597](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805084732597.png)

![image-20210805084751205](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805084751205.png)

## 数据仓库规范

### 1、设计规范

​	数据埋点规范

​	数仓层次设计

​	数据采集规范

### 2、命名规范

​		根据业务过程，抽象基本术语单元

​		对相应的术语单元做语义翻译，可以采用拼音、英文、含义数字，但避免英文、拼音混用

​		拼音、英文尽量在不失愿意的情况下采用缩写形式

​		避免数字开头

![image-20210805085536895](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805085536895.png)

​	表命名规范

| 数据域     | 数仓层次     | 周期/数据范围  |
| ---------- | ------------ | -------------- |
| 订单:order | 共用维度:dim | 日期快照:d     |
| 用户:user  | 集市:dm      | 增量:i         |
| 财务:finc  | ods:o        | 周:w           |
|            | dwd:d        | 拉链表:l       |
|            | edw:e        | 非分区全量表:a |

表命名规范

能够合理的区分出表所描述的数据域、数据周期等

命名：层次_数据域_修饰/描述_范围/zhouq 

​	订单相关数据表

​	dwd层：d_ord_info_d

​	edw层：e_ord_st_d



​	对于ods层表，最好能够区分数据来源，包括在来自什么系统、源数据名称

​	eg.从业务系统全量采集订单(loan_order)数据到ods层

​	业务系统编码：buss

​	业务系统订单表：loan_order

​	ods层表命名：o_buss_loan_order_d



**字段命名**

设计模型的时候，按照业务含义、业务术语规范命名字段汉字名称

避免数字开头

同一业务含义统一命名。避免不同表达方式

统一书写格式，比如用户id：user_id，用户姓名：userName非统一格式

统一大小写，建议统一小写

避免与关键字、自定义udf重名

用户_ID   user_id		应还__金额  ar_amt

实还_金额  act_amt	逾期__利息 oveduce_int

下单_计数 crt_ord_cnt	月___下单____计数m_crt_ord_cnt

累积_下单__用户_计数 total_crt_ord_user_cnt

**脚本命名规范**

- ETL脚本名称尽可能和所产出的表同名
- 数据采集、数据推送脚本尽可能标识数据去向
- ETL脚本若产生多个表，采用对应的数据域和语义描述命名
- Jar包命名以实际的业务处理逻辑语义描述为主，调度任务命名同样尽量以产出表名命名

订单ETL过程：从表o_buss_loan_order_d整理数据并且装载到dwd层表d_ord_ino_d中

ETL脚本命名：d_ord_info_d.sh

​						 d_ord_info_d.py

​						 d_ord_info_d.hql

​						 d_ord_info_d.jar

ETL任务命名：d_ord_info_d

一个ETL脚本产出多个表，比如从商品表中分离出商品维度、厂商维度

ETL脚本命名：dim_product_mfrs_d.sh  	

​						 dim_product_mfrs_d.py

​					     dim_product_mfrs_d.hql

​						 dim_product_mfrs_d.jar

ETL任务命名：dim_product_mfrs_d



采集数据到ods层的表o_buss_loan_order_d

imp_o_buss_loan_order_d.sh  imp_o_buss_loan_order_d.py

数据表dm_ord_trsfm_d推送到BI系统

exp_dm_ord_trsfm_d.sh exp_dm_ord_trsfm_d.py



### 3、开发规范

数仓中MR程序尽可能统一输入参数、输出参数，单个jar程序的功能模块清晰，避免多种处理逻辑写入一个jar包

每个ETL脚本尽可能产出一张数仓表，方便任务排查，同时也减少数仓表的耦合性

ETL脚本格式、备注清晰，避免大范围、格式杂乱的脚本，合理利用临时表

​		字段列对齐

​		关键字对齐

​		禁止使用Tab，全部使用4个空格代替

![image-20210805095115468](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805095115468.png)

Sqoop脚本

```sql
sqoop import \
--connect jdbc:mysql://loaclhost:3306/finc?autoReconnect=true \
--driver com.mysql.jdbc.Driver \
--username root \
--password root \
--query "select user_id,user_name,sex,id_card,bank_no,mobile,created_time,updated_time from finc.user_info where $CONDITIONS" \
--delete-target-dir \
--target-dir /user/hive/warehouse/ods_tinc.db/o_buss_user_info_d/dt=${1} \
--hive-import \
--hive-overwrite \
--hive-database ods_finc \
--hive-table o_buss_user_info_d \
--hive-partition-key dt \
--hive-partition-value {1} \
--fields-terminated-by "\\0001" \
--lines--terminated-by "\n" \
--null-string '\\N' \
--null-non-string '\\N' \
--split-by id user_id \
--m 4

stage 

sqoop import \
--connect jdbc:mysql://loaclhost:3306/finc?autoReconnect=true \
--driver com.mysql.jdbc.Driver \
--username root \
--password root \
--query 'select order_id,user_id,created_time,updated_time from finc.loan_order where updated_time>="2018-06-09 00:00:00" $CONDITIONS' \
--delete-target-dir \
--target-dir /user/hive/warehouse/stage.db/o_buss_stage_d/dt=${1} \
--hive-import \
--hive-overwrite \
--hive-database stage \
--hive-table o_buss_stage_d \
--hive-partition-key dt \
--hive-partition-value {1} \
--fields-terminated-by "\\0001" \
--lines--terminated-by "\n" \
--null-string '\\N' \
--null-non-string '\\N' \
--split-by id updated_time \
--m 4

sqoop import \
--connect jdbc:mysql://loaclhost:3306/finc?autoReconnect=true \
--driver com.mysql.jdbc.Driver \
--username root \
--password root \
--query "select user_id,user_name,sex,id_card,bank_no,mobile,created_time,updated_time from finc.user_info_log where updated_time>='2018-06-09 00:00:00' $CONDITIONS" \
--delete-target-dir \
--target-dir /user/hive/warehouse/ods_tinc.db/o_buss_user_info_log_i/dt=${1} \
--hive-import \
--hive-overwrite \
--hive-database ods_finc \
--hive-table o_buss_user_info_log_i \
--hive-partition-key dt \
--hive-partition-value {1} \
--fields-terminated-by "\\0001" \
--lines--terminated-by "\n" \
--null-string '\\N' \
--null-non-string '\\N' \
--split-by id user_id \
--m 4
```

```sql
dim_user_d
user_id,user_name,sex,birth_date,mob_num,created_time,updated_time,load_time 
dim_product_d
product_id,term,dur

ods_finc.o_buss_loan_order_d
order_id,user_id,amount,svr_charge,created_time,updated_time

select 
ta.*,
case when product_id=''  then interest*365
	 when product_id=''  then interest*365
	 else interest
	 end as interest
	 ,tb.sex
	 ,tb.mob_num
	 ,tc.term
	 ,tc.dur
	 from 
(select * from ods_finc.o_buss_loan_order_d
where dt='') ta 
left join
(select * from dim_user_d where dt='') tb
on ta.user_id = tb.user_id
left join
(select * from dim_product_d dt='') tc 
on ta.product_id = tc.product_id

dwd.d_ord_info_d
order_id,user_id,sex,mob_num,term,dur,amount,svr_charge,created_time,updated_time,load_time

dwd.d_ord_bill_d
bill_id,order_id,user_id,sex,mob_num,term,dur,seq,amount,status(0未到期  1已还  2逾期  3逾期已还)

edw.e_ord_st_d

(select 
order_id,user_id,sex,mob_num,term,dur,amount,svr_charge,created_time,updated_time,load_time,
lead() over(partition by user_id order by created_time asc ) as last_create_time) ta 
left join 
(select
order_id,
sum(case status=2 then 1 else 0 end) as overdue_bill_cnt,
sum(case status=2 then amt else 0 end) as overdue_amt
from 
dw.d_ord_bill_d where dt='') tb
```





## 十二、数据治理

### 1、数据治理之数仓架构设计先行

**数据治理的痛点**

| 痛点                                 | 解决                                                   |
| ------------------------------------ | ------------------------------------------------------ |
| 数据库、表命名管理乱                 | **逻辑分层** 制定规范 约束建表流程和命名，迁移老业务   |
| 烟囱式开发，数据孤岛                 | **维度建模** 主题划分 数据结构简单 分析灵活多样化      |
| 找数难，用表难，不敢用               | **数据地图** 收集表，任务元数据，追溯数据血缘关系      |
| 指标定义不统一，重复开发，数据不一致 | **指标字典** OneData体系，命名规范管理统一口径规则     |
| 敏感数据泄露风险，集群存储空间告警   | **数据治理** 仅限访问控制 数据生命周期                 |
| DB表全量同步效率低，影响业务上线     | **增量抽取** 设计拉链表 后期考虑订阅binlog日志增量消费 |
| 业务方自建数据仓库                   | **开放共享** 共享DW层 自建ADS层                        |
| 数据开发新人如何上手                 | **培训宣贯** 拉齐认知 新员工入职培训和数仓开发流程宣贯 |

​	数据分层架构

![image-20210804192612227](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804192612227.png)

数仓构建核心流程

![image-20210804193045827](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804193045827.png)

需求标准化

![image-20210804193925553](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804193925553.png)

人：业务方PM/需求方PM

![image-20210804194439928](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804194439928.png)

指标管理

![image-20210804194747532](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804194747532.png)

事实表管理

![image-20210804195320195](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804195320195.png)

指标审核

![image-20210804195753276](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804195753276.png)

维度管理

![image-20210804200057832](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804200057832.png)

原子指标管理

![image-20210804200240357](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804200240357.png)

时间周期管理

![image-20210804200634022](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804200634022.png)

指标管理应用

![image-20210804200738299](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804200738299.png)

建模管理

数仓建模核心流程之数仓主题表维度建模

![image-20210804204001376](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804204001376.png)

![image-20210804204829073](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804204829073.png)

![image-20210804204849524](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804204849524.png)

**建库建表规范**

建库规范

![image-20210804205708303](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804205708303.png)

数据表规范

![image-20210804205815673](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804205815673.png)

字段规范

![image-20210804205948773](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804205948773.png)

数据地图

![image-20210804210238834](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804210238834.png)

![image-20210804212827583](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804212827583.png)

数据源-建表

![image-20210804213112617](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804213112617.png)

数据源-任务逻辑

![image-20210804213306276](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804213306276.png)



### 2、数据治理值数据治理方法论

数据治理3W1H方法论

![image-20210804221037534](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804221037534.png)

数据治理是什么？

![image-20210804221247962](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804221247962.png)

数据治理目标

![image-20210804221534641](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804221534641.png)

存储的安全、传输的安全、展示的安全

数据治理的时机

![image-20210804221821129](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804221821129.png)

数据治理标准之埋点标准

![image-20210804222124719](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210804222124719.png)

数据治理标准之业务标准

![image-20210805113325034](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805113325034.png)

![image-20210805134142235](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805134142235.png)![image-20210805134221808](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805134221808.png)

数据生命周期管理

![image-20210805134325137](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805134325137.png)

数据安全标准

![image-20210805134739177](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805134739177.png)

数据治理如何做

数据治理实施之技术架构治理

![image-20210805134829919](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805134829919.png)

![image-20210805135337584](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805135337584.png)

![image-20210805135445876](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805135445876.png)

![image-20210805135528100](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805135528100.png)

元数据治理

![image-20210805142838672](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805142838672.png)

数据安全

![image-20210805143056436](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805143056436.png)

任务治理

![image-20210805143404097](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805143404097.png)

数据质量管理

![image-20210805143456620](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210805143456620.png)